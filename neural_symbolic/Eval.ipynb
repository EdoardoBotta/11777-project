{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "93d38efa-cc02-4641-b3d4-e8b48ef2a1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5473fe55-0349-4a6f-919d-1c17adef6d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wino_amrs.jsonl') as f:\n",
    "    gt_amrs = [json.loads(l) for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "169c9488-0ecf-49b0-aa56-f4e871f21490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to your output parse file\n",
    "with open('sample_outputs/wino_blip2-flant5xl_caps_parse.jsonl') as f:\n",
    "    cand_amrs = [json.loads(l) for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ece425a0-2865-47de-be60-3106be33c0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_amrs = gt_amrs[:len(cand_amrs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7591d4e7-b944-47be-8c12-86253d0275fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE=len(cand_amrs[0]['parses_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "98394a62-9f5a-4122-8489-87af308d807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_score(candidate,ground_truth):\n",
    "    full_score=!python smatch/smatch.py -f {candidate} {ground_truth}  --ms | cut -d ':' -f2\n",
    "    return list(map(float,full_score))\n",
    "\n",
    "def full_score_recall(candidate,ground_truth):\n",
    "    full_score=!python smatch/smatch.py -f {candidate} {ground_truth}  --ms --pr | grep Recall | cut -d ':' -f2\n",
    "    return list(map(float,full_score))\n",
    "\n",
    "def rel_score(candidate,ground_truth):\n",
    "    just_rel=!python smatch/smatch.py -f {candidate} {ground_truth} --ms --justrelation | cut -d ':' -f2\n",
    "    return list(map(float,just_rel))\n",
    "\n",
    "def attr_score(candidate,ground_truth):\n",
    "    just_attr=!python smatch/smatch.py -f {candidate} {ground_truth} --ms --justattribute | cut -d ':' -f2\n",
    "    return list(map(float,just_attr))\n",
    "\n",
    "def inst_score(candidate,ground_truth):\n",
    "    just_inst=!python smatch/smatch.py -f {candidate} {ground_truth} --ms --justinstance | cut -d ':' -f2\n",
    "    return list(map(float,just_inst))\n",
    "\n",
    "smatch_score_map = {\n",
    "    'full':full_score,\n",
    "    'full_recall':full_score_recall,\n",
    "    'rel':rel_score,\n",
    "    'attr':attr_score,\n",
    "    'inst':inst_score\n",
    "}\n",
    "\n",
    "def get_smatch_scores_from_file(ground_truth_path,candidate_path,method='full'):\n",
    "    if method not in score_map:\n",
    "        raise ValueError(\"invalid smatch score method\")\n",
    "    return smatch_score_map[method](candidate_path,ground_truth_path)\n",
    "\n",
    "def save_tmp_amr(f1,f2,ground_truth_path,candidate_path):\n",
    "    with open(ground_truth_path,'w') as f, open(candidate_path,'w') as g:\n",
    "        for p0,p1 in zip(f1,f2):\n",
    "            print(p0,file=f)\n",
    "            print(p1,file=g)\n",
    "            \n",
    "def get_smatch_scores(f1,f2,method='full'):\n",
    "    candidate_path=\"cand_test.amr\"\n",
    "    ground_truth_path=\"gt_test.amr\"\n",
    "    save_tmp_amr(f1,f2,ground_truth_path,candidate_path)\n",
    "    return get_smatch_scores_from_file(ground_truth_path,candidate_path,method='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e0f82ace-61ef-4429-b4d4-ad4cf96070d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "409f23a0-9b53-41d9-a1fe-0634b7e1d983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_handles(gt_amrs,cand_amrs):\n",
    "    fc0=[gt_amr['parse_0'] for gt_amr in gt_amrs for _ in range(SAMPLE_SIZE)]\n",
    "    fi0=[p for cand_amr in cand_amrs for p in cand_amr['parses_0']]\n",
    "    fc1=[gt_amr['parse_1'] for gt_amr in gt_amrs for _ in range(SAMPLE_SIZE)]\n",
    "    fi1=[p for cand_amr in cand_amrs for p in cand_amr['parses_1']]\n",
    "    return fc0,fc1,fi0,fi1\n",
    "\n",
    "def get_pair_scores(scoring_func,fc0,fc1,fi0,fi1):\n",
    "    s00 = list(scoring_func(fc0,fi0))\n",
    "    s01 = list(scoring_func(fc0,fi1))\n",
    "    s10 = list(scoring_func(fc0,fi1))\n",
    "    s11 = list(scoring_func(fc1,fi1))\n",
    "    return s00,s01,s10,s11\n",
    "\n",
    "def get_text_score(s00,s01,s10,s11):\n",
    "    # s00 = score(C0,I0)\n",
    "    # text score == given image, pick caption\n",
    "    counts = [c0>x0 and c1>x1 for c0,x0,c1,x1 in zip(s00,s10,s11,s01)]\n",
    "    return sum(counts)/len(counts),counts\n",
    "\n",
    "def get_image_score(s00,s01,s10,s11):\n",
    "    counts = [c0>x0 and c1>x1 for c0,x0,c1,x1 in zip(s00,s01,s11,s10)]\n",
    "    return sum(counts)/len(counts),counts\n",
    "\n",
    "def get_group_score(s00,s01,s10,s11):\n",
    "    counts = [c00>x01 and c00>x10 and c11>x01 and c11>x10 for c00,x01,c11,x10 in zip(s00,s01,s11,s10)]\n",
    "    return sum(counts)/len(counts),counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "22a0b886-12a5-4b8b-84d0-4ac1fe063dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc0,fc1,fi0,fi1 = get_handles(gt_amrs,cand_amrs)\n",
    "score_func=lambda f1,f2:get_smatch_scores(f1,f2,method='rel')\n",
    "s00,s01,s10,s11 = get_pair_scores(score_func,fc0,fc1,fi0,fi1)\n",
    "text_score,txt_cnt=get_text_score(s00,s01,s10,s11)\n",
    "im_score,im_cnt=get_image_score(s00,s01,s10,s11)\n",
    "gp_score,gp_cnt=get_group_score(s00,s01,s10,s11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "78d62919-84d4-4c5a-aa7a-c0a6a6f7c214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.085 0.0845 0.0815\n"
     ]
    }
   ],
   "source": [
    "print(text_score,im_score,gp_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6008c6a6-c216-4375-9220-d1f3f89749ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.54, 0.36, 0.5, 0.36)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s00[0],s10[0],s11[0],s01[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eeee3b-9ba4-424d-8a2e-9867ec70ec13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amr",
   "language": "python",
   "name": "cenv_x86"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
