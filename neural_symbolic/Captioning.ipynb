{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7076f3af-bda5-4b9d-9e1a-bee349d86b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, Blip2ForConditionalGeneration\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c08a0d9d-1951-4ddd-bcaa-37fcb919aac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69c53cd4bfd4310a25e4ecfdcb327c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/432 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7763408b53754ad48eb9b1b486f35416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/904 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a680d6c3bf04a239c6d3a515429a98a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba972e2688c4bf0abd2beef5284794e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67edf97dd0e14951936fbfed393c2026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d74ad71638f4c95af8d202208465ba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/548 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70fdadeac3a6465fad3e5577aef807e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/6.95k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c26e8c422904ebcb67f9f34c82688de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin.index.json:   0%|          | 0.00/122k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e559a9b7786d4f6d9f8b59b141def042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecacd8b51cad4963bffd3d5d11aab0e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00004.bin:   0%|          | 0.00/9.80G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7212cf0ea9244848adb391dde3078cb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00004.bin:   0%|          | 0.00/9.93G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63de3632aa92406188f6b8d80a701cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00003-of-00004.bin:   0%|          | 0.00/9.93G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75cbae928fa045169271eb48cef9099b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00004-of-00004.bin:   0%|          | 0.00/2.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58def718de1546ed9c08eb8a3e1d54d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pip install accelerate bitsandbytes\n",
    "import torch\n",
    "import requests\n",
    "from PIL import Image\n",
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "\n",
    "# model_name=\"Salesforce/blip2-flan-t5-xl\"\n",
    "model_name=\"Salesforce/blip2-opt-6.7b-coco\"\n",
    "processor = Blip2Processor.from_pretrained(model_name)\n",
    "model = Blip2ForConditionalGeneration.from_pretrained(model_name, load_in_8bit=True, device_map=\"auto\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fbe8c5-3c5f-48b1-b565-3bcbed3e9f55",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c36f4846-5a3d-4fff-9f98-1caab7fdcf3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "playing with a woman on the beach\n"
     ]
    }
   ],
   "source": [
    "# img_url = 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/demo.jpg' \n",
    "# raw_image = Image.open(requests.get(img_url, stream=True).raw).convert('RGB')\n",
    "\n",
    "# question = \"give a caption describing the action of the dog\"\n",
    "\n",
    "# # Image captioning (without providing a text prompt):\n",
    "# inputs = processor(raw_image, question, return_tensors=\"pt\").to(\"cuda\", torch.float16)\n",
    "\n",
    "# out = model.generate(**inputs)\n",
    "# print(processor.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1fe8553-cb44-4eee-8069-f10a3d986eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "woman playing with dog on beach\n"
     ]
    }
   ],
   "source": [
    "# img_url = 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/demo.jpg' \n",
    "# raw_image = Image.open(requests.get(img_url, stream=True).raw).convert('RGB')\n",
    "\n",
    "# # Image captioning (without providing a text prompt):\n",
    "# inputs = processor(raw_image, return_tensors=\"pt\").to(\"cuda\", torch.float16)\n",
    "\n",
    "# out = model.generate(**inputs)\n",
    "# print(processor.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "155060e6-d4c6-4683-82ae-6f4c0fc34f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Half Precision\n",
    "# processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-flan-t5-xl\")\n",
    "# model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-flan-t5-xl\", torch_dtype=torch.float16, device_map=\"auto\")\n",
    "\n",
    "# img_url = 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/demo.jpg' \n",
    "# raw_image = Image.open(requests.get(img_url, stream=True).raw).convert('RGB')\n",
    "\n",
    "# question = \"how many dogs are in the picture?\"\n",
    "# inputs = processor(raw_image, question, return_tensors=\"pt\").to(\"cuda\", torch.float16)\n",
    "\n",
    "# Full Precision\n",
    "# model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-flan-t5-xl\", device_map=\"auto\")\n",
    "# question = \"how many dogs are in the picture?\"\n",
    "# inputs = processor(raw_image, question, return_tensors=\"pt\").to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2addf3aa-809f-4738-9b2b-86dce6baf043",
   "metadata": {},
   "source": [
    "### Winoground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2a145ea-6794-425f-9ff6-0238a9709fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "load_dotenv()  # This loads the environment variables from .env\n",
    "\n",
    "api_key = os.getenv('HGF_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "544e6042-4fec-44f3-bf04-f30c770bd349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52dc19897ea140c48dc3725b493cc67e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "667276dfbb1b4456a87d9581e46be4e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/4.13k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d0e7eecfd3e47ffb5fc68c37e668644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0af767946de4f21b6bd162705253a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/115k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a460ebc14c4a92a6a6a2ddc020c145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/364M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea02e1522ca44f9aa01bee9d08f31f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca2b287afcc4b11a9215632cbba8198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "winoground = load_dataset('facebook/winoground', token=api_key)['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0b882a2-41b5-4c9d-88d7-50cf6b0b4c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE=5\n",
    "NUM_BEAMS=5\n",
    "DO_SAMPLE=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "562a5bb7-3a85-402f-91e1-2f220aa806e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a man in a cowboy hat kissing a little girl on the cheek\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example = winoground[0]\n",
    "# winoground dataset images are already in RGB mode\n",
    "raw_image_0 = example['image_0'] \n",
    "# Image captioning (without providing a text prompt):\n",
    "inputs = processor(raw_image_0, return_tensors=\"pt\").to(\"cuda\", torch.float16)\n",
    "\n",
    "out = model.generate(**inputs,do_sample=True,num_beams=5,num_return_sequences=SAMPLE_SIZE,\n",
    "temperature=1)\n",
    "print(processor.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a505c408-523c-48a1-8f97-fef56dc5c370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a man in a cowboy hat kissing a little girl on the cheek\n",
      "\n",
      "a man in cowboy hat kissing a little girl on the cheek\n",
      "\n",
      "a man in cowboy hat kissing a little girl on the cheek\n",
      "\n",
      "a man in a cowboy hat kissing a young girl on the cheek\n",
      "\n",
      "a man in cowboy hat kissing a young girl on the cheek\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for o in out:\n",
    "    print(processor.decode(o, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87a060a3-8c61-4cc7-a39a-ec57049dcaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_on_data(winoground,f_stream):\n",
    "    for example in tqdm(winoground):\n",
    "        d = {}\n",
    "        d['id'] = example['id']\n",
    "    \n",
    "        for i in range(2):     \n",
    "            raw_image = example[f'image_{i}'] \n",
    "            inputs = processor(raw_image, return_tensors=\"pt\").to(\"cuda\", torch.float16)\n",
    "            out = model.generate(**inputs,do_sample=DO_SAMPLE,\n",
    "                                   num_beams=NUM_BEAMS,num_return_sequences=SAMPLE_SIZE)\n",
    "            d[f'caption_{i}'] = [processor.decode(o, skip_special_tokens=True) for o in out]\n",
    "    \n",
    "        print(json.dumps(d),file=f_stream,flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb199b85-2549-405d-a63c-5295891ff97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                  | 0/400 [00:00<?, ?it/s]/mnt/efs/fs1/mmml/miniconda3/envs/cenv_x86/lib/python3.8/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████████████████████████| 400/400 [35:07<00:00,  5.27s/it]\n"
     ]
    }
   ],
   "source": [
    "with open(f'wino_{model_name}_caps.jsonl','w') as f:\n",
    "    generate_on_data(winoground,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "882a2095-1d78-40cf-99d4-869aa15011c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import smatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3079d84-2841-4d0f-99e3-dcd7068817b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module smatch:\n",
      "\n",
      "NAME\n",
      "    smatch\n",
      "\n",
      "DESCRIPTION\n",
      "    This script computes smatch score between two AMRs.\n",
      "    For detailed description of smatch, see http://www.isi.edu/natural-language/amr/smatch-13.pdf\n",
      "\n",
      "FUNCTIONS\n",
      "    compute_f(match_num, test_num, gold_num)\n",
      "        Compute the f-score based on the matching triple number,\n",
      "                                     triple number of AMR set 1,\n",
      "                                     triple number of AMR set 2\n",
      "        Args:\n",
      "            match_num: matching triple number\n",
      "            test_num:  triple number of AMR 1 (test file)\n",
      "            gold_num:  triple number of AMR 2 (gold file)\n",
      "        Returns:\n",
      "            precision: match_num/test_num\n",
      "            recall: match_num/gold_num\n",
      "            f_score: 2*precision*recall/(precision+recall)\n",
      "    \n",
      "    compute_match(mapping, weight_dict)\n",
      "        Given a node mapping, compute match number based on weight_dict.\n",
      "        Args:\n",
      "        mappings: a list of node index in AMR 2. The ith element (value j) means node i in AMR 1 maps to node j in AMR 2.\n",
      "        Returns:\n",
      "        matching triple number\n",
      "        Complexity: O(m*n) , m is the node number of AMR 1, n is the node number of AMR 2\n",
      "    \n",
      "    compute_pool(instance1, attribute1, relation1, instance2, attribute2, relation2, prefix1, prefix2, doinstance=True, doattribute=True, dorelation=True)\n",
      "        compute all possible node mapping candidates and their weights (the triple matching number gain resulting from\n",
      "        mapping one node in AMR 1 to another node in AMR2)\n",
      "        \n",
      "        Arguments:\n",
      "            instance1: instance triples of AMR 1\n",
      "            attribute1: attribute triples of AMR 1 (attribute name, node name, attribute value)\n",
      "            relation1: relation triples of AMR 1 (relation name, node 1 name, node 2 name)\n",
      "            instance2: instance triples of AMR 2\n",
      "            attribute2: attribute triples of AMR 2 (attribute name, node name, attribute value)\n",
      "            relation2: relation triples of AMR 2 (relation name, node 1 name, node 2 name\n",
      "            prefix1: prefix label for AMR 1\n",
      "            prefix2: prefix label for AMR 2\n",
      "        Returns:\n",
      "          candidate_mapping: a list of candidate nodes.\n",
      "                           The ith element contains the node indices (in AMR 2) the ith node (in AMR 1) can map to.\n",
      "                           (resulting in non-zero triple match)\n",
      "          weight_dict: a dictionary which contains the matching triple number for every pair of node mapping. The key\n",
      "                       is a node pair. The value is another dictionary. key {-1} is triple match resulting from this node\n",
      "                       pair alone (instance triples and attribute triples), and other keys are node pairs that can result\n",
      "                       in relation triple match together with the first node pair.\n",
      "    \n",
      "    generate_amr_lines(f1, f2)\n",
      "        Read one AMR line at a time from each file handle\n",
      "        :param f1: file handle (or any iterable of strings) to read AMR 1 lines from\n",
      "        :param f2: file handle (or any iterable of strings) to read AMR 2 lines from\n",
      "        :return: generator of cur_amr1, cur_amr2 pairs: one-line AMR strings\n",
      "    \n",
      "    get_amr_match(cur_amr1, cur_amr2, sent_num=1, justinstance=False, justattribute=False, justrelation=False)\n",
      "    \n",
      "    get_best_gain(mapping, candidate_mappings, weight_dict, instance_len, cur_match_num)\n",
      "        Hill-climbing method to return the best gain swap/move can get\n",
      "        Arguments:\n",
      "        mapping: current node mapping\n",
      "        candidate_mappings: the candidates mapping list\n",
      "        weight_dict: the weight dictionary\n",
      "        instance_len: the number of the nodes in AMR 2\n",
      "        cur_match_num: current triple match number\n",
      "        Returns:\n",
      "        the best gain we can get via swap/move operation\n",
      "    \n",
      "    get_best_match(instance1, attribute1, relation1, instance2, attribute2, relation2, prefix1, prefix2, doinstance=True, doattribute=True, dorelation=True)\n",
      "        Get the highest triple match number between two sets of triples via hill-climbing.\n",
      "        Arguments:\n",
      "            instance1: instance triples of AMR 1 (\"instance\", node name, node value)\n",
      "            attribute1: attribute triples of AMR 1 (attribute name, node name, attribute value)\n",
      "            relation1: relation triples of AMR 1 (relation name, node 1 name, node 2 name)\n",
      "            instance2: instance triples of AMR 2 (\"instance\", node name, node value)\n",
      "            attribute2: attribute triples of AMR 2 (attribute name, node name, attribute value)\n",
      "            relation2: relation triples of AMR 2 (relation name, node 1 name, node 2 name)\n",
      "            prefix1: prefix label for AMR 1\n",
      "            prefix2: prefix label for AMR 2\n",
      "        Returns:\n",
      "            best_match: the node mapping that results in the highest triple matching number\n",
      "            best_match_num: the highest triple matching number\n",
      "    \n",
      "    main(arguments)\n",
      "        Main function of smatch score calculation\n",
      "    \n",
      "    move_gain(mapping, node_id, old_id, new_id, weight_dict, match_num)\n",
      "        Compute the triple match number gain from the move operation\n",
      "        Arguments:\n",
      "            mapping: current node mapping\n",
      "            node_id: remapped node in AMR 1\n",
      "            old_id: original node id in AMR 2 to which node_id is mapped\n",
      "            new_id: new node in to which node_id is mapped\n",
      "            weight_dict: weight dictionary\n",
      "            match_num: the original triple matching number\n",
      "        Returns:\n",
      "            the triple match gain number (might be negative)\n",
      "    \n",
      "    normalize(item)\n",
      "        lowercase and remove quote signifiers from items that are about to be compared\n",
      "    \n",
      "    print_alignment(mapping, instance1, instance2)\n",
      "        print the alignment based on a node mapping\n",
      "        Args:\n",
      "            mapping: current node mapping list\n",
      "            instance1: nodes of AMR 1\n",
      "            instance2: nodes of AMR 2\n",
      "    \n",
      "    random_init_mapping(candidate_mapping)\n",
      "        Generate a random node mapping.\n",
      "        Args:\n",
      "            candidate_mapping: candidate_mapping: candidate node match list\n",
      "        Returns:\n",
      "            randomly-generated node mapping between two AMRs\n",
      "    \n",
      "    score_amr_pairs(f1, f2, justinstance=False, justattribute=False, justrelation=False)\n",
      "        Score one pair of AMR lines at a time from each file handle\n",
      "        :param f1: file handle (or any iterable of strings) to read AMR 1 lines from\n",
      "        :param f2: file handle (or any iterable of strings) to read AMR 2 lines from\n",
      "        :param justinstance: just pay attention to matching instances\n",
      "        :param justattribute: just pay attention to matching attributes\n",
      "        :param justrelation: just pay attention to matching relations\n",
      "        :return: generator of cur_amr1, cur_amr2 pairs: one-line AMR strings\n",
      "    \n",
      "    smart_init_mapping(candidate_mapping, instance1, instance2)\n",
      "        Initialize mapping based on the concept mapping (smart initialization)\n",
      "        Arguments:\n",
      "            candidate_mapping: candidate node match list\n",
      "            instance1: instance triples of AMR 1\n",
      "            instance2: instance triples of AMR 2\n",
      "        Returns:\n",
      "            initialized node mapping between two AMRs\n",
      "    \n",
      "    swap_gain(mapping, node_id1, mapping_id1, node_id2, mapping_id2, weight_dict, match_num)\n",
      "        Compute the triple match number gain from the swapping\n",
      "        Arguments:\n",
      "        mapping: current node mapping list\n",
      "        node_id1: node 1 index in AMR 1\n",
      "        mapping_id1: the node index in AMR 2 node 1 maps to (in the current mapping)\n",
      "        node_id2: node 2 index in AMR 1\n",
      "        mapping_id2: the node index in AMR 2 node 2 maps to (in the current mapping)\n",
      "        weight_dict: weight dictionary\n",
      "        match_num: the original matching triple number\n",
      "        Returns:\n",
      "        the gain number (might be negative)\n",
      "\n",
      "DATA\n",
      "    DEBUG_LOG = <ipykernel.iostream.OutStream object>\n",
      "    ERROR_LOG = <ipykernel.iostream.OutStream object>\n",
      "    iteration_num = 5\n",
      "    match_triple_dict = {}\n",
      "    pr_flag = False\n",
      "    single_score = True\n",
      "    verbose = False\n",
      "    veryVerbose = False\n",
      "\n",
      "FILE\n",
      "    /mnt/efs/fs1/mmml/miniconda3/envs/cenv_x86/lib/python3.8/site-packages/smatch.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(smatch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amr",
   "language": "python",
   "name": "cenv_x86"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
